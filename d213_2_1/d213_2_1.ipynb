{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789b830d",
   "metadata": {},
   "source": [
    "# D213 Task 2 Rev 1 - Mattinson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc09f37",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7775ffd",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# install tensorflow\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6645e78",
   "metadata": {},
   "source": [
    "!pip install nlp"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f82bf12",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# install keras - this is actually part of the tensorflow install...\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e0194",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a8cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#import nlp\n",
    "#import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de0c2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9eaa5e",
   "metadata": {},
   "source": [
    "## Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c8748d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read three .csv files - with headers UTF-8\n",
    "# had to do some minor edits in EXCEL first\n",
    "amazon = pd.read_csv('data/amazon.csv')\n",
    "imdb =  pd.read_csv('data/imdb.csv')\n",
    "yelp =  pd.read_csv('data/yelp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd434156",
   "metadata": {},
   "source": [
    "## Combine dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a307028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a col 'source' to remember where the data came from\n",
    "amazon['Source'] = 'Amazon'\n",
    "imdb['Source'] = 'Imdb'\n",
    "yelp['Source'] = 'Yelp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94f0ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine three dataframes\n",
    "df = pd.concat([amazon, imdb, yelp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ba1129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns, if not already done\n",
    "df = df.rename(columns={0: 'Sentence', 1: 'Score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d12677a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index 0..2999\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "580f7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  3000 non-null   object\n",
      " 1   Score     3000 non-null   int64 \n",
      " 2   Source    3000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac61ef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>It fits comfortably in either ear, the sound i...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Nice Sound.</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>To call this movie a drama is ridiculous!</td>\n",
       "      <td>0</td>\n",
       "      <td>Imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>Unless you're just out to visually \"collect\" a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "      <td>Imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>Both of them were truly unbelievably good, and...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>Eclectic selection.</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Score  Source\n",
       "0     So there is no way for me to plug it in here i...      0  Amazon\n",
       "333   It fits comfortably in either ear, the sound i...      1  Amazon\n",
       "666                                         Nice Sound.      1  Amazon\n",
       "999   You can not answer calls with the unit, never ...      0  Amazon\n",
       "1332        To call this movie a drama is ridiculous!        0    Imdb\n",
       "1665  Unless you're just out to visually \"collect\" a...      0    Imdb\n",
       "1998                               Exceptionally bad!        0    Imdb\n",
       "2331  Both of them were truly unbelievably good, and...      1    Yelp\n",
       "2664                                Eclectic selection.      1    Yelp\n",
       "2997  Overall I was not impressed and would not go b...      0    Yelp"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show sample from dataframe\n",
    "df.iloc[::333, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38a123",
   "metadata": {},
   "source": [
    "## Natural Language (Prasad, 2020) week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9efa9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sentences - training data\n",
    "sentences = list(df['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2ca33cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ... 61  5  1]\n",
      " [ 0  0  0 ...  1 92  1]\n",
      " [ 0  0  0 ... 13  2  1]\n",
      " ...\n",
      " [ 0  0  0 ... 14 76 70]\n",
      " [ 0  0  0 ...  1  1 41]\n",
      " [ 0  0  0 ...  1  2  1]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences)\n",
    "#print(word_index)\n",
    "#print(sequences)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "213b1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_data = [\n",
    "    ' i really love my dog',\n",
    "    'my dog loves my mom'\n",
    "    'you love my mom',\n",
    "    'do you think my do is amazing?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86682108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 48, 78, 17, 1], [17, 1, 1, 17, 1, 78, 17, 1], [94, 22, 1, 17, 94, 6, 1]]\n"
     ]
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "print(test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c174364",
   "metadata": {},
   "source": [
    "## tensorflow.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a51f66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in w:\\code\\wgu\\py39\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_hub) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_hub) (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d8d31a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in w:\\code\\wgu\\py39\\lib\\site-packages (4.5.2)\n",
      "Requirement already satisfied: tqdm in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (4.64.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (2.27.1)\n",
      "Requirement already satisfied: absl-py in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-metadata in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (3.19.4)\n",
      "Requirement already satisfied: numpy in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (1.22.3)\n",
      "Requirement already satisfied: dill in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (0.3.5.1)\n",
      "Requirement already satisfied: six in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: promise in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: termcolor in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in w:\\code\\wgu\\py39\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in w:\\code\\wgu\\py39\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in w:\\code\\wgu\\py39\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in w:\\code\\wgu\\py39\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in w:\\code\\wgu\\py39\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.2)\n",
      "Requirement already satisfied: colorama in w:\\code\\wgu\\py39\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cedc8d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.9.1\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" \n",
    "      if tf.config.list_physical_devices('GPU') \n",
    "      else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d275d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_venv",
   "language": "python",
   "name": "py39_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
